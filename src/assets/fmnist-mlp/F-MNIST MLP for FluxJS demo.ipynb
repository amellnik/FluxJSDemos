{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-MNIST Multilayer Perceptron\n",
    "This notebook uses [Flux](https://github.com/FluxML/Flux.jl) to train a multilayer perceptron on the [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset.  It exports the trained model with [FluxJS](https://github.com/FluxML/FluxJS.jl) to [deeplearn.js](https://deeplearnjs.org/) so that it can be used in the browser.  \n",
    "\n",
    "(Credit for this notebook goes to [WooKyoung Noh](https://github.com/wookay))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehotbatch, argmax, crossentropy, throttle, @epochs\n",
    "using BSON\n",
    "using Base.Iterators: repeated\n",
    "using FluxJS\n",
    "using MLDatasets # FashionMNIST\n",
    "using ColorTypes: N0f8, Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 32, NNlib.relu), Dense(32, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const Img = Matrix{Gray{N0f8}}\n",
    "\n",
    "function prepare_train()\n",
    "    # load full training set\n",
    "    train_x, train_y = FashionMNIST.traindata() # 60_000\n",
    "\n",
    "    trainrange = 1:6_000 # 1:60_000\n",
    "    imgs = Img.([train_x[:,:,i] for i in trainrange])\n",
    "    # Stack images into one large batch\n",
    "    X = hcat(float.(reshape.(imgs, :))...) # |> gpu\n",
    "    # One-hot-encode the labels\n",
    "    Y = onehotbatch(train_y[trainrange], 0:9) # |> gpu\n",
    "    X, Y\n",
    "end\n",
    "\n",
    "function prepare_test()\n",
    "    # Load full test set\n",
    "    test_x,  test_y  = FashionMNIST.testdata() # 10_000\n",
    "\n",
    "    testrange = 1:1_000 # 1:10_000\n",
    "    test_imgs = Img.([test_x[:,:,i] for i in testrange])\n",
    "    tX = hcat(float.(reshape.(test_imgs, :))...) # |> gpu\n",
    "    tY = onehotbatch(test_y[testrange], 0:9) #|> gpu\n",
    "    \n",
    "    # Save the first 100 images in a bson for use in the web demo\n",
    "    bson(\"test_images.bson\", Dict(\n",
    "        :images => reshape(Float32.(tX[:,1:100]), 784*100),\n",
    "        :labels =>Int32.(test_y[1:100])\n",
    "    ))\n",
    "    \n",
    "    tX, tY\n",
    "end\n",
    "\n",
    "X, Y = prepare_train()\n",
    "tX, tY = prepare_test()\n",
    "\n",
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) #|> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 1\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 2.2092898282431657 (tracked)\n",
      "loss(X, Y) = 0.7711078301661559 (tracked)\n",
      "loss(X, Y) = 0.5753037785678004 (tracked)\n",
      "loss(X, Y) = 0.4886423081057284 (tracked)\n",
      "loss(X, Y) = 0.43305247741176495 (tracked)\n",
      "loss(X, Y) = 0.39058106078322763 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 2\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 0.3782079092994961 (tracked)\n",
      "loss(X, Y) = 0.3482974056880615 (tracked)\n",
      "loss(X, Y) = 0.3216500239810373 (tracked)\n",
      "loss(X, Y) = 0.2972648955063786 (tracked)\n",
      "loss(X, Y) = 0.2746521381826436 (tracked)\n",
      "loss(X, Y) = 0.25406525767792704 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 3\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 0.24590414591071832 (tracked)\n",
      "loss(X, Y) = 0.2292228276802084 (tracked)\n",
      "loss(X, Y) = 0.2139464663078373 (tracked)\n",
      "loss(X, Y) = 0.20096482093341603 (tracked)\n",
      "loss(X, Y) = 0.18836702544141706 (tracked)\n",
      "loss(X, Y) = 0.1757916763713962 (tracked)\n",
      "loss(X, Y) = 0.16621841612299457 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 4\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 0.15601178095725948 (tracked)\n",
      "loss(X, Y) = 0.14648761848005154 (tracked)\n",
      "loss(X, Y) = 0.13735999868574397 (tracked)\n",
      "loss(X, Y) = 0.1288889449222339 (tracked)\n",
      "loss(X, Y) = 0.12104516419992967 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 5\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 0.11598446578921456 (tracked)\n",
      "loss(X, Y) = 0.10890311641299735 (tracked)\n",
      "loss(X, Y) = 0.10323907165672414 (tracked)\n",
      "loss(X, Y) = 0.09795740634899289 (tracked)\n",
      "loss(X, Y) = 0.09286789322018227 (tracked)\n",
      "loss(X, Y) = 0.08781265548413232 (tracked)\n",
      "Training set accuracy: 0.9836666666666667\n",
      "Test set accuracy: 0.837\n"
     ]
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(argmax(m(x)) .== argmax(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM(params(m))\n",
    "\n",
    "@epochs 5 Flux.train!(loss, dataset, opt, cb = throttle(evalcb, 2))\n",
    "\n",
    "println(\"Training set accuracy: \", accuracy(X, Y))\n",
    "# 0.983\n",
    "\n",
    "println(\"Test set accuracy: \", accuracy(tX, tY))\n",
    "# 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "let model = (function () {\n",
       "  let math = dl.ENV.math;\n",
       "  function barracuda(gnat) {\n",
       "    return math.add(math.matrixTimesVector(model.weights[0], gnat), model.weights[1]);\n",
       "  };\n",
       "  function barracuda(grouse) {\n",
       "    return math.relu(math.add(math.matrixTimesVector(model.weights[2], grouse), model.weights[3]));\n",
       "  };\n",
       "  function model(nightingale) {\n",
       "    return math.softmax(barracuda(barracuda(nightingale)));\n",
       "  };\n",
       "  model.weights = [];\n",
       "  return model;\n",
       "})();\n",
       "flux.fetchWeights(\"model.bson\").then((function (ws) {\n",
       "  return model.weights = ws;\n",
       "}));\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the deeplearn.js representation of the model\n",
    "@code_js m(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the model javascript and the model weights to files\n",
    "FluxJS.compile(\"mlp\", m, X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
